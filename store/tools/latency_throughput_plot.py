# This script creates latency vs throughput plots.
#
# A latency vs throughput plot is a scatterplot. Each point at position (x, y)
# represents a measured throughput of x and a latency of y. Typically, a
# latency vs throughput plot has a handful of labels, and each point is
# associated with a particular label. For example, you may have the latency and
# throughput of TAPIR, of MongoDB, and of Postgres on the same plot. Moreover,
# each of the points is generated by a workload with certain parameters. For
# example, one point may have been measured with 10 clients, while another
# point may have been measured with 1000 clients.
#
# You run this script like this:
#
#   python latency_throughput_plot.py some_data.csv \
#     --group_by zipf_coefficient \
#     --ignore num_clients \
#     --ignore num_keys
#
# This creates a throughput vs latency plot with labels drawn from the column
# `zipf_coefficient`. There is one plot generated for every setting of
# independent variables, except that the columns specified using `--ignore` are
# ignored. For example, if we ran the following experiments:
#
#   - zipf_coefficient=0, num_clients=1, num_keys=10, num_server_threads=1
#   - zipf_coefficient=0, num_clients=2, num_keys=10, num_server_threads=1
#   - zipf_coefficient=0, num_clients=1, num_keys=20, num_server_threads=1
#   - zipf_coefficient=0, num_clients=2, num_keys=20, num_server_threads=1
#   - zipf_coefficient=1, num_clients=1, num_keys=10, num_server_threads=1
#   - zipf_coefficient=1, num_clients=2, num_keys=10, num_server_threads=1
#   - zipf_coefficient=1, num_clients=1, num_keys=20, num_server_threads=1
#   - zipf_coefficient=1, num_clients=2, num_keys=20, num_server_threads=1
#   - zipf_coefficient=0, num_clients=1, num_keys=10, num_server_threads=2
#   - zipf_coefficient=0, num_clients=2, num_keys=10, num_server_threads=2
#   - zipf_coefficient=0, num_clients=1, num_keys=20, num_server_threads=2
#   - zipf_coefficient=0, num_clients=2, num_keys=20, num_server_threads=2
#   - zipf_coefficient=1, num_clients=1, num_keys=10, num_server_threads=2
#   - zipf_coefficient=1, num_clients=2, num_keys=10, num_server_threads=2
#   - zipf_coefficient=1, num_clients=1, num_keys=20, num_server_threads=2
#   - zipf_coefficient=1, num_clients=2, num_keys=20, num_server_threads=2
#
# and ran the command above, we would get two plots: one for
# num_server_threads=1 and one for num_server_threads=2. Both plots would have
# two labels: one for zipf_coefficient=0, and one for zipf_coefficient=1. Each
# label would have four data points.

from textwrap import wrap
from typing import Any, Dict, Iterable, List, NamedTuple, Set, Tuple
import argparse
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd

def sanitize(x: Any) -> Any:
    if isinstance(x, float):
        return '%.1f' % x
    else:
        return x

def plot(filename: str,
         label: Dict[str, Any],
         df: pd.DataFrame,
         group_by: str) -> None:
    matplotlib.rc('font', size=12)
    fig, ax = plt.subplots()

    grouped = df.groupby(group_by)
    for (name, group) in grouped:
        ax.scatter(group['throughput_success'],
                   group['average_latency_all'],
                   label=f'{group_by}={sanitize(name)}')

    suffix = ""
    if len(label) > 0:
        suffix = ', '.join(f'{k}={sanitize(v)}' for (k, v) in label.items())
        suffix = f' ({suffix})'
    title = f'Latency vs throughput{suffix}'
    ax.set_title('\n'.join(wrap(title, 40)))
    ax.set_xlabel('Throughput (transactions per second)')
    ax.set_ylabel('Latency (ms)')
    ax.grid()
    ax.legend(loc='best')
    fig.set_tight_layout(True)
    fig.savefig(filename)
    print(f'Saved figure to {filename}.')
    plt.close()

def main(data_filename: str, group_by: str, ignore_columns: List[str]) -> None:
    # Read in the data to a dataframe.
    df = pd.read_csv(data_filename)
    df['num_clients'] = (df['num_client_machines'] *
                         df['num_clients_per_machine'] *
                         df['num_threads_per_client'])

    # Every experiment records a set of outputs for various values of
    # independent variables (e.g., throughput and latency for various values of
    # num_server_threads and zipf_coefficient). We create a throughput vs
    # latency graph with respect to the column `with_respect_to`. We create one
    # such plot for every setting of independent variables.
    ignore: Set[str] = {
        group_by,
        # Ignore num_client_machines, num_clients_per_machine, and
        # num_threads_per_client because we have 'num_clients'.
        'num_client_machines',
        'num_clients_per_machine',
        'num_threads_per_client',
    }
    ignore |= set(ignore_columns)
    outputs = {
        'num_transactions',
        'num_successful_transactions',
        'num_failed_transactions',
        'abort_rate',
        'throughput_all',
        'throughput_success',
        'throughput_failure',
        'average_latency_all',
        'median_latency_all',
        'average_latency_success',
        'median_latency_success',
        'average_latency_failure',
        'median_latency_failure',
    }
    varied_columns = [c for c in df
                      if df[c].nunique() > 1 and
                      c not in ignore | outputs]
    if varied_columns:
        print('Varied columns:')
        for c in varied_columns:
            print(f'- {c}')

    # Create the charts.
    if varied_columns:
        grouped = df.groupby(varied_columns)
        for (name, group) in grouped:
            if type(name) != list and type(name) != tuple:
                name = [name]
            label = {k: v for (k, v) in zip(varied_columns, name)}
            suffix = '_'.join(f'{k}={v}' for (k, v) in label.items())
            filename = f'latency_throughput_{suffix}.pdf'
            plot(filename, label, group, group_by)
    else:
        filename = f'latency_throughput.pdf'
        plot(filename, dict(), df, group_by)

def get_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        'data',
        type=str,
        help='Experiment data')
    parser.add_argument(
        '--group_by',
        '-g',
        type=str,
        required=True,
        help='The column to group by')
    parser.add_argument(
        '--ignore',
        '-i',
        type=str,
        default=[],
        action='append',
        help='The columns to ignore')
    return parser

if __name__ == '__main__':
    parser = get_parser()
    args = parser.parse_args()
    main(args.data, args.group_by, args.ignore)
